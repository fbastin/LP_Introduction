\documentclass[t,usepdftitle=false]{beamer}

\usepackage[utf8]{inputenc}
\usepackage[french]{babel}

\usetheme{Singapore}
\usepackage{xcolor}

% \setbeamercovered{transparent}
%\usecolortheme{crane}
\title[Introduction points intérieurs]{Points intérieurs\\Introduction}
\author[Fabian Bastin]{Fabian Bastin\\DIRO\\Université de Montréal}
\date{}

\usepackage{ulem}
\usepackage{cancel}

\usepackage{amsmath}
\newtheorem{thm}{Théorème}

\setbeamertemplate{footline}[frame number]

\usepackage{tikz}
\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
    \node[shape=circle,draw,inner sep=2pt] (char) {#1};}}

\def\ba{\boldsymbol{a}}
\def\bb{\boldsymbol{b}}
\def\bc{\boldsymbol{c}}
\def\be{\boldsymbol{e}}
\def\br{\boldsymbol{r}}
\def\bs{\boldsymbol{s}}
\def\bu{\boldsymbol{u}}
\def\bx{\boldsymbol{x}}
\def\by{\boldsymbol{y}}
\def\bz{\boldsymbol{z}}
\def\bA{\boldsymbol{A}}
\def\bB{\boldsymbol{B}}
\def\bD{\boldsymbol{D}}
\def\bH{\boldsymbol{H}}
\def\bI{\boldsymbol{I}}
\def\bL{\boldsymbol{L}}
\def\bM{\boldsymbol{M}}
\def\bU{\boldsymbol{U}}
\def\bzero{\boldsymbol{0}}
\def\bone{\boldsymbol{1}}
\def\blambda{\boldsymbol{\lambda}}

\def\cA{\mathcal{A}}
\def\cN{\mathcal{N}}
\def\cR{\mathcal{R}}

\def\RR {\mathcal{R}}

\begin{document}
\frame{\titlepage}

% ------------------------------------------------------------------------------------------------------------------------------------------------------\begin{frame}

\begin{frame}
\frametitle{Vitesse de convergence du simplexe}

On sait que la procédure du simplexe converge vers une solution optimale (en supposant qu'au moins une telle solution existe) en un nombre fini d'étapes. Il n'est reste pas moins que ce nombre d'étapes peut être grand.

%\mbox{}

%Soit $n$ le nombre de variables et $m$ le nombre de contraintes linéaires, avec $m \leq n$. Il peut y avoir jusqu'à $n!/(m!(n-m)!$) bases à considérer, bien que certaines ne soient pas réalisables et pourront donc être écartées.

\mbox{}

Peut-il arriver que le simplexe examine toutes les bases réalisables possibles? La réponse est malheureusement oui.

\mbox{}

En général, le simplexe est une méthode rapide. Mais pour une instance donnée, nous n'avons aucune garantie.
\end{frame}

\begin{frame}
\frametitle{Eléments de la théorie de complexité}

Complexité: quantité de ressources requises par un calcul.

\mbox{}

But: associer à un algorithme des mesures intrinsèques de ses exigences en temps de calcul. Grosso-modo, pour ce faire, nous avons besoin de définir
\begin{itemize}
\item
une notion de la taille des entrées;
\item
un ensemble d'opérations de base;
\item
un coût pour chaque opération de base.
\end{itemize}

\mbox{}

Si $x$ est une entrée donnée, le coût de calcul $C(x)$ avec l'entrée $x$ est la somme des coûts de toutes les opérations de base utilisées au cours de ce calcul.

\end{frame}

\begin{frame}
\frametitle{Eléments de la théorie de complexité}

Soit $\mathcal{A}$ un algorithme et $\mathcal{J}_n$ l'ensemble de toutes les entrées de taille $n$. La fonction de coût de pire cas de $\mathcal{A}$ est définie par
\[
T^w_{\mathcal{A}}(n) = \sup_{x \in \mathcal{J}_n} C(x).
\]

\mbox{}

S'il existe une structure de probabilités définie sur $\mathcal{J}_n$, il est possible de définir le coût moyen comme
\[
T^a_{\mathcal{A}}(n) = E_{x \in \mathcal{J}_n} [C(x)].
\]
où $E_{x \in \mathcal{J}_n}$ est l'espérance sur $\mathcal{J}_n$.

\mbox{}

Ce coût moyen est souvent plus difficile à obtenir.

\end{frame}

\begin{frame}
\frametitle{Eléments de la théorie de complexité}

Comment sélectionner les trois types d'objet définis plus haut pour l'analyse?

\mbox{}

Pour les algorithmes que nous considérons ici, le choix évident est l'ensemble des quatre opérations algorithmiques de base:\\
$+$, $-$, $\times$, $/$.

\mbox{}

Sélectionner une notion de taille d'entrée et de coût pour les opérations de base dépend du type de données traitées par l'algorithme. Certains types peuvent être représentés à l'intérieur d'une quantité fixée de mémoire informatique, tandis que d'autres nécessitent une mémoire variable.

\end{frame}

\begin{frame}
\frametitle{Eléments de la théorie de complexité}

Un concept de base est celui de temps polynomial.

\mbox{}

Un algorithme $\mathcal{A}$ est dit algorithme en temps polynomial si $T_{\mathcal{A}}^w(n)$ est bornée supérieurement par un polynôme.

\mbox{}

Un problème peut être résolu en temps polynomial s'il existe un algorithme en temps polynomial résolvant le problème.

\mbox{}

La notion de temps moyen polynomial est définie similairement, en remplaçant $T_{\mathcal{A}}^w(n)$ par $T_{\mathcal{A}}^a(n)$.

\mbox{}

La notion de temps polynomial est généralement prise comme la formalisation de l'efficacité en théorie de la complexité.

\end{frame}

\begin{frame}
\frametitle{La méthode du simplexe n'est pas en temps polynomial}

Soit $A \in \cR^{m \times n}$, $b \in \cR^m$, $c \in \cR^n$.

\mbox{}

Le nombre d'étapes de pivots est typiquement un petit multiple de $n$. Toutefois, le nombre d'itérations requises peut être exponentiel.

\mbox{}

Une forme de l'exemple de Klee-Minty est
\begin{align*}
\max_x \ & \sum_{j =1}^n 10^{n-j} x_j \\
\mbox{t.q. } & 2\sum_{j = 1}^{i-1} 10^{i-j} x_j + x_i \leq 100^{i-1},\ i = 1,\ldots, n\\
& x_j \geq 0,\ j = 1,\ldots, n.
\end{align*}

\end{frame}

\begin{frame}
\frametitle{Exemple de Klee-Minty}

Considérons le cas $n = 3$.
\begin{align*}
\max_x \ & 100x_1 + 10x_2 + x_3\\
& x_1 \leq 1 \\
& 20 x_1 + x_2 \leq 100 \\
& 200 x_1 + 20 x_2 + x_3 \leq 10000 \\
& x_1 \geq 0,\ x_2 \geq 0,\ x_3 \geq 0.
\end{align*}

\mbox{}

Sous forme standard, cela donne $m = 3$, $n = 6$, comme nous devons ajouter 3 variables d'écart. On peut montrer que 7 pivots sont nécessaires.

\end{frame}

\begin{frame}
\frametitle{Exemple de Klee-Minty}

Sous la forme générale, cela donne $2^n - 1$ pivots.

\mbox{}

Pour $n = 50$, cela donne $2^{50} - 1 \approx 10^{15}$. Si on était capable de réaliser un million de pivots par seconde, il faudrait aux environs de 33 ans pour résoudre le problème.

\end{frame}

%\begin{frame}
%\frametitle{Un peu d'histoire}

% Pris de https://www.stat.cmu.edu/~ryantibs/convexopt-S15/lectures/16-primal-dual.pdf
%\begin{itemize}
%\item 
%Dantzig (1940s): the simplex method. Still one of the most popular algorithms for linear programming.
%\item
%Klee and Minty (1960s): LP with $n$ variables and $2^n$ constraints that the simplex method needs to perform $2^n$ iterations to solve.
%\item 
%Khachiyan (1979): first polynomial-time algorithm for LP based on the ellipsoid method of Nemirovski and Yudin (1976). Theoretically strong but computationally weak.
%\item
%Karmarkar (1984): first interior-point polynomial-time algorithm for LP.
%\item 
%Renegar (1988): Newton-based interior-point algorithm for LP. Best known theoretical complexity to date.
%\item
%Modern state-of-the-art LP solvers typically use both simplex and interior-point methods.
%\end{itemize}

%\end{frame}

\begin{frame}
\frametitle{Méthodes de points intérieurs: complémentarité}

(Vanderbei) Pourquoi les problèmes linéaires sont-ils difficiles? En raison de la complémentarité!

\mbox{}

Reprenons la paire primale-duale
\begin{align*}
\min_x\ & c^T x \\
\mbox{s.c. } & Ax = b \\
& x \geq 0,
\end{align*}
\begin{align*}
\max_{\lambda} \  & b^T \lambda \\
\mbox{s.c. } & A^T \lambda  +t = c. \\
& t \geq 0
\end{align*}
Nous avions obtenu
\[
t_i x_i = 0, \ i = 1,\ldots, n.
\]

\end{frame}

\begin{frame}
\frametitle{Méthodes de points intérieurs: complémentarité}

On peut aussi le voir sur la forme symétrique:
\begin{align*}
\min_x\ & c^T x \\
\mbox{s.c. } & Ax - u = b \\
& x \geq 0,\ u \geq 0.
\end{align*}
\begin{align*}
\max_{\lambda} \  & b^T \lambda \\
\mbox{s.c. } & A^T \lambda  +t = c. \\
& \lambda \geq 0, t \geq 0.
\end{align*}
Dans ce cas, nous avons
\[
t_i x_i = 0,\ i = 1,\ldots,n \quad
\lambda_j u_j = 0,\ j = 1,\ldots, m.
\]

\end{frame}

\begin{frame}
\frametitle{Notation matricielle}

On ne peut écrire $tx = 0$, comme le produit $tx$ est indéfini.

\mbox{}

Réécriture:
\[
x = \begin{pmatrix}
x_1 \\ x_2 \\ x_3 \\ \vdots \\ x_n
\end{pmatrix}
\Rightarrow
\begin{pmatrix}
x_1 \\ & x_2 \\ & & x_3 \\ & & & \ddots \\ & & & & x_n
\end{pmatrix}
\]

\mbox{}

Les conditions de complémentarité peuvent alors être réécrites comme
\[
XTe = 0,\quad U\Lambda e = 0.
\]
\end{frame}

\begin{frame}
\frametitle{Conditions d'optimalité}

\begin{align*}
Ax - u &= b \\
A^T \lambda + t &= c \\
XTe &= 0\\
U\Lambda e &= 0\\
x,\ \lambda,\ t,\ u &\geq 0.
\end{align*}

\mbox{}

Ignorons (temporairement) les contraintes de non-négativité.
Nous avons $2n + 2m$ équations, à $2n + 2m$ inconnues.

\mbox{}

Soucis: le système n'est pas linéaire. La non-linéarité des conditions de complémentarité rend le problème de programmation linéaire fondamentalement plus difficile que la résolution d'un système d'équations linéaires.

\end{frame}

\begin{frame}
\frametitle{Conditions d'optimalité: $\mu$-complémentarité}

En plus d'ignorer les contraintes de non-négativité, on va relâcher les contraintes de complémentarité en utilisant un paramètre $\mu > 0$:
\begin{align*}
Ax - u &= b \\
A^T \lambda + t &= c \\
XTe &= \mu e\\
U\Lambda e &= \mu e.
\end{align*}
Les paires de variables primales duales contiennent deux variables de même nature et fixer la valeur d'une variable fixe la seconde (alors qu'une valeur nulle laisse l'autre variable indéterminée).

\end{frame}

\begin{frame}
\frametitle{Direction de recherche}

Débuter avec une solution initiale positive $(x, \lambda, u, t)$.

\mbox{}

On va introduire des directions de recherche
\[
\Delta x,\ \Delta \lambda,\ \Delta u,\ \Delta t,
\]
et on réécrit les équations précédentes avec
\[
x + \Delta x,\ \lambda + \Delta \lambda,\ u + \Delta u,\ t + \Delta t,
\]
Cela donne
\begin{align*}
A(x + \Delta x) - (u + \Delta u) &= b \\
A^T (\lambda + \Delta \lambda) + (t + \Delta t) &= c \\
(X + \Delta X)(T + \Delta T)e &= \mu e\\
(U + \Delta U)(\Lambda + \Delta \Lambda)e &= \mu e.
\end{align*}

\end{frame}

\begin{frame}
\frametitle{Direction de recherche}

On réarrange avec les variables ``$\Delta$'' à gauche, les autres termes à droite, et on ``jette'' les termes non-linéaires:
\begin{align*}
A\Delta x - \Delta u &= b - Ax + u\\
A^T\Delta \lambda + \Delta t &= c - A^T\lambda - t \\
T\Delta X + X \Delta T &= \mu e - TXe \\
U\Delta \Lambda + \Lambda \Delta U  &= \mu e - U\Lambda e.
\end{align*}

\mbox{}

C'est un système linéaire de $2m + 2n$ équations à $2m + 2n$ inconnues, que nous pouvons résoudre, pour définir
\begin{align*}
x &\leftarrow x + \alpha \Delta x \\
\lambda &\leftarrow \lambda + \alpha \Delta \lambda \\
u &\leftarrow u + \alpha \Delta u \\
t &\leftarrow t + \alpha \Delta t \\
\end{align*}
$\alpha$ est un paramètre qui sert à maintenir $x$, $\lambda$, $t$, $u$, $t$ positifs.

\end{frame}

\begin{frame}
\frametitle{Forcer la convergence}

Prendre une plus petite value de $\mu$ pour la prochaine itération.

\mbox{}

Répéter à partir du début, jusqu'à ce que la solution courante satisfasse, avec une certaine tolérance, les conditions d'optimalité suivantes;
\begin{itemize}
\item
Réalisabilité primale: $b - Ax + u = 0$;
\item
Réalisabilité duale: $c - A^T\lambda - t = 0$;
\item
Écart de dualité: $b^T \lambda - c^Tx = 0$.
\end{itemize}

\mbox{}

\end{frame}

\begin{frame}
\frametitle{Forcer la convergence}

\begin{thm}
\begin{itemize}
\item
La non-réalisabilité primale devient plus petite d'un facteur $1 - \alpha$ à chaque itération.
\item
La non-réalisabilité duale devient plus petite d'un facteur $1 - \alpha$ à chaque itération.
\item
Si le primal et le dual sont réalisable, l'écart de dualité diminue d'un facteur $1-\alpha$ à chaque itération (si $\mu = 0$, et une convergence légèrement plus lente si $\mu > 0$).
\end{itemize}
\end{thm}


Pas si simple!

\mbox{}

L'algorithme travaille itérativement, en calcul un pas à chaque itération, mais comment est-mis à jour le paramètre $\alpha$? Comment choisir et mettre à jour $\mu$?

\end{frame}

\begin{frame}
	\frametitle{Méthode affine primale}
	
	Section basée sur les notes de Gilles Savard: \url{http://www.iro.umontreal.ca/~marcotte/Ift6511/Pts_interieurs.pdf}.
	
	Voir aussi \url{https://nptel.ac.in/courses/106108056/module9/LinearProgramming_IV.pdf}

\mbox{}
	
	\begin{itemize}
		\item 
		Présentée uniquement comme introduction aux méthodes de points intérieurs.
		\item
		Méthode simple et relative efficacité pratique.
		\item
		La complexité polynomiale n’est pas connue pour l'approche primale (ou duale).
		\item
		Analyse de convergence complexe.
	\end{itemize}
	
\end{frame}

\begin{frame}
	\frametitle{Principe}
	
	L'approche consiste à calculer une direction de descente (i.e. qui permet de réduire la valeur de l'objectif) qui n’approche pas trop rapidement
	de la frontière.
	%Cette direction de plus forte descente est calcul´ee `a partir d’un probl`eme mis `a l’´echelle qui centre la solution courante et qui est ensuite transform´ee dans l’espace original.
	
	\mbox{}
	
	Trois étapes:
	\begin{enumerate}
		\item 
		calcul de la direction de descente,
		\item
		calcul du pas,
		\item
		calcul de la transformation affine.
	\end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{Intérieur de l'ensemble des contraintes}
	
	Considérons l'ensemble réalisable défini de manière général par des contraintes d'égalité et des contraintes d'inégalité:
	$$
	\cA = \left\{ x \,\bigg|\, \begin{cases}
		g_i(x) = 0,\ i = 1,\ldots,m \\
		h_j(x) \geq 0,\ j = 1,\ldots,n
	\end{cases}
	\right\}
	$$
	
	L'intérieur de $\cA$, noté notamment $int \cA$, est
	$$
	int \cA = \left\{ x \,\bigg|\, \begin{cases}
		g_i(x) = 0,\ i = 1,\ldots,m \\
		h_j(x) > 0,\ j = 1,\ldots,n
	\end{cases}
	\right\}
	$$
	
	Avec un problème linéaire sous forme standard, nous avons
	$$
	\cA = \{ x \,|\, Ax = b,\ x \geq 0 \}
	$$
	et
	$$
	int\cA = \{ x \,|\, Ax = b,\ x > 0 \}.
	$$
	
\end{frame}

\begin{frame}
	\frametitle{Formulation}
	
	Considérons à nouveau le primal
	\begin{align*}
		\min_x \ & c^Tx \\
		\mbox{t.q. } & Ax = b\\
		& x \geq 0,
	\end{align*}
	avec $A$ de rang plein. On suppose aussi que $\cA$ et $int\cA$ sont non vides.
	
\end{frame}

\begin{frame}
	\frametitle{Direction de descente}
	
	Soit $x_c$ le point courant t.q.
	$$
	Ax_c = b, \ x_c > 0.
	$$

	On cherche
	$$
	x^+ = x_c + \alpha \Delta x \quad \text{ t.q. }\quad 
	c^Tx^+ \leq c^T x_c,\ Ax^+ = b.
	$$
	Le déplacement doit donc vérifier
	\begin{align*}
		& c^T \Delta x \leq 0 \\
		& Ax^+ = A(x_c + \alpha \Delta x) = b
	\end{align*}
	
\end{frame}

\begin{frame}
	\frametitle{Direction de descente}
	
	Sous l'hypothèse que $\alpha > 0$, $\Delta x$ doit être dans le noyau de $A$, i.e.
	$$
	\Delta x \in \cN(A) = \{x \in \RR^n \,|\, Ax = 0 \}.
	$$
	La direction de plus forte descente est donnée par
	\begin{align*}
		\min_{\Delta x}\ & c^T\Delta x \\
		\mbox{t.q. } & A \Delta x = 0 \\
		& \| \Delta x \| = 1.
	\end{align*}
	La solution est
	$$
	\frac{\text{proj}_A(-c)}{\| \text{proj}_A (-c) \|} = \Delta x,
	$$
	$\text{proj}_A(\cdot)$ étant la matrice orthogonale de projection sur le
	noyau de $A$.
	
\end{frame}

\begin{frame}
	\frametitle{Direction de descente}
	
	Comme $A$ est de plein rang et en oubliant la normalisation, il est possible de montrer que
	$$
	\Delta x = \text{proj}_A(-c) = -(I - A^T(AA^T)^{-1}A)c.
	$$
	
	\mbox{}
	
	Note: une matrice orthogonale de projection $P$ sur le noyau de $A$ vérifie les propriétés suivantes:
	\begin{align*}
		AP &= 0 \\
		P &= P^T \\
		P^2 &= P.
	\end{align*}
	Notons $P = I - A^T(AA^T)^{-1}A$. Alors
$$
		c^T \Delta x = -c^T P c = -c^T P^2 c = - \| Pc \|^2_2 \leq 0.
$$
	
\end{frame}

\begin{frame}
	\frametitle{Longueur de pas}
	
	Le taux de décroissance est constant dans la direction $\Delta x$.
	Le pas maximal est limité par les contraintes de non-négativité.
	De plus, la transformation affine qui nous permettra de centrer le point n'est pas définie sur la frontière.
	
	\mbox{}
	
	Il suffit de choisir
	$$
	\alpha = \gamma\alpha_{\max},
	$$
	avec $0 < \gamma < 1$, et
	$$
	\alpha_{\max} = \min_{\Delta x_i < 0} \frac{-(x_c)_i}{\Delta x_i}.
	$$
	En pratique, on choisit $\gamma  = 0.995$.
	Si $\Delta x \geq 0$ et $\Delta x \ne 0$, le problème est non borné.
	
\end{frame}

\begin{frame}
	\frametitle{Transformation affine}
	
	Il s'agit de faire une mise à l'échelle afin que le nouveau point $x^+$ soit loin de la frontière définie par $x \geq 0$.
	
	\mbox{}
	
	Un point idéal serait le vecteur unitaire $e$. Ainsi, on cherche une transformation
	affine qui transforme $x^+$ en $e$.
	La matrice de transformation est simplement l'inverse de la matrice diagonale dont les
	composantes sont les mêmes que celles de $x^+$ (qui sont $>0$).
	Notons cette matrice par $X$.
	On a alors $X^{-1}x^+ = e$, et notons
	$$
	X^{-1}x = \overline{x}.
	$$
	
	\mbox{}
	
	Dans l'espace transformé, le programme devient
	\begin{align*}
		\min_{\overline{x}} \ & c^TX\overline{x} = \overline{c}^T\overline{x} \\
		\mbox{t.q. } & AX\overline{x} = \overline{A}\overline{x} = b\\
		& \overline{x} \geq 0.
	\end{align*}
	
\end{frame}

\begin{frame}
	\frametitle{Calcul du nouveau point}
	
	Dans l'espace-$\overline{x}$, on obtient % et étant donné $\overline{x}_c e$, on obtient
	\begin{align*}
		\Delta\overline{x} &= \text{proj}_{\overline{A}}(-\overline{c}) \\
		& = -(I - \overline{A}^T(\overline{A}\overline{A}^T)^{-1}\overline{A})\overline{c} \\
		& = -(I - XA^T(AX^2A^T)^{-1}AX)Xc
	\end{align*}
	et
	$$
	\overline{x}^+ = \overline{x}_c + \alpha \Delta \overline{x},
	$$
	d'où
	\begin{align*}
		x^+ &= X\overline{x}^+ \\
		&= x_c + \alpha X \Delta \overline{x} \\
		&= x_c - \alpha X(I - XA^T(AX^2A^T)^{-1}AX)Xc.
	\end{align*}
	
\end{frame}

\begin{frame}
	\frametitle{Convergence}
	
	Supposons $A$ plein rang, qu'il existe un point strictement intérieur et que la fonction objectif est non constante sur le domaine réalisable.
	Alors
	\begin{enumerate}
		\item
		Si le problème primal et le problème dual sont non dégénérés, alors pour tout $\gamma < 1$, la suite générée par l'algorithme converge vers une solution optimale.
		\item
		Pour $\gamma \leq 2/3$, la suite produite par l’algorithme converge
		vers une solution optimale (y compris en présence de dégénérescence).
	\end{enumerate}
	
	Preuve: admis!
	
\end{frame}

\begin{frame}
	\frametitle{Critère d’arrêt}
	
	Basé sur la satisfaction des conditions d'optimalité.
	
	\mbox{}
	
	Considérons d’abord le cas non dégénéré (primal et dual).
	
	\mbox{}
	
	Programme dual:
	\begin{align*}
		\max_{y,s} \ & b^Ty \\
		\mbox{t.q. } & A^Ty + s = c \\
		& s \geq 0.
	\end{align*}
	Soit $x_k$ la solution courante et considérons le programme
	\begin{align*}
		\min_{y,s} \ & \| X_ks \| \\
		\mbox{t.q. } & A^Ty + s = c \\
		& s \geq 0.
	\end{align*}
	
\end{frame}

\begin{frame}
	\frametitle{Critère d’arrêt}
	
	Problème non linéaire!
		
	\mbox{}
	
	Il est possible de montrer que la solution est donnée par
	\begin{align*}
		y_k &= (AX^2_kA^T)^{-1}AX^2_kc \\
		s_k &= c - A^Tyk
	\end{align*}
	Dès lors
	$$
	s_k = c - A^T(AX^2_kA^T)^{-1}AX^2_kc = (I - A^T(AX^2_kA^T)^{-1}AX^2_k)c
	$$
	et
	\begin{align*}
		-X^2_ks_k &= -X^2_k(I - A^T(AX^2_kA^T)^{-1}AX^2_k)c \\
		&= -X_k(I - X_kA^T(AX^2_kA^T)^{-1}AX_k)X_kc \\
		&= \Delta x_k.
	\end{align*}
	Le vecteur dual est obtenu comme sous-produit du calcul
	de la direction de descente.
	
\end{frame}

\begin{frame}
	\frametitle{Convergence}
	
	Sous l'hypothèse de non dégénérescence primale et duale, la solution $(y_k, s_k)$ converge vers la solution optimale duale lorsque $x_k$ converge vers la solution optimale primale.
	
	\mbox{}
	
	Dans ce cas, un critère d'arrêt peut être défini sur la norme
	du vecteur de complémentarité.
	
	\mbox{}
	
	Dans le cas dégénéré, la convergence de $(y_k, s_k)$ n'est pas assurée, et un critère d'arrêt classique sur l'amélioration successive de deux itérés est utilisé.
	
\end{frame}

\begin{frame}
	\frametitle{Algorithme}
	
	Soit $\gamma \in (0,1)$, $\epsilon > 0$ et un point initial $x_0$.
	Poser
	\begin{align*}
		x_c &:= x_0 \\
		\Delta c &:= \epsilon|c^Tx_c|+2
	\end{align*}
	Tant que $\Delta c > \epsilon\max\{|c^Tx_c|,1\}$ répéter
	\begin{align*}
		X &:= X_c \\
		\Delta x &:= -X(I - XA^T(AX^2A^T)^{-1}AX)Xc \\
		\alpha &:= \gamma \min_{\Delta x_i < 0} \frac{-(x_c)_i}{\Delta x_i} \\
		x^+ &:= x_c + \alpha \Delta x \\
		% \alpha &:= \gamma \min_{\Delta x_i < 0} \frac{-1}{\Delta x_i} \\
		% x^+ &:= x_c + \alpha X \Delta x \\
		\Delta c &:= c^Tx_c - c^Tx^+ \\
		x_c &:= x^+.
	\end{align*}
	
\end{frame}

\begin{frame}
	\frametitle{Algorithme}
	
	On peut légèrement simplifier les opérations comme suit.
	
	Soit $\gamma \in (0,1)$, $\epsilon > 0$ et un point initial $x_0$.
	Poser
	\begin{align*}
		x_c &:= x_0 \\
		\Delta c &:= \epsilon|c^Tx_c|+2
	\end{align*}
	Tant que $\Delta c > \epsilon\max\{|c^Tx_c|,1\}$ répéter
	\begin{align*}
		X &:= X_c \\
		\Delta x &:= -(I - XA^T(AX^2A^T)^{-1}AX)Xc \\
		%\alpha &:= \gamma \min_{\Delta x_i < 0} \frac{-(x_c)_i}{\Delta x_i} \\
		%x^+ &:= x_c + \alpha \Delta x \\
		\alpha &:= \gamma \min_{\Delta x_i < 0} \frac{-1}{\Delta x_i} \\
		x^+ &:= x_c + \alpha X \Delta x \\
		\Delta c &:= c^Tx_c - c^Tx^+ \\
		x_c &:= x^+.
	\end{align*}
	
\end{frame}

\end{document}
